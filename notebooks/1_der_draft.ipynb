{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esthy13/cil-intrusion-detection/blob/main/der_draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkCuth4CTgIB"
      },
      "source": [
        "# DER++ for Intrusion Detection (CIC-IDS)\n",
        "\n",
        "Minimal **working** implementation of **Dark Experience Replay++**\n",
        "for class-incremental intrusion detection."
      ],
      "id": "NkCuth4CTgIB"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "383d2c74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "383d2c74",
        "outputId": "2a8870ca-f6fa-4e0a-9282-651909ddc447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cil-intrusion-detection' already exists and is not an empty directory.\n",
            "/content/cil-intrusion-detection\n",
            "Already up to date.\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/esthy13/cil-intrusion-detection\n",
        "%cd cil-intrusion-detection\n",
        "!git pull\n",
        "# resetting the path to content to avoid issues in the rest of the notebook\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "EOVxYZQ2TgID"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "id": "EOVxYZQ2TgID"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDA-qUhCTgID"
      },
      "source": [
        "## Dataset"
      ],
      "id": "RDA-qUhCTgID"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nGoN76koTgID"
      },
      "outputs": [],
      "source": [
        "class IDSBaseDataset(Dataset):\n",
        "    def __init__(self, root_dir, split=\"train\"):\n",
        "        \"\"\"\n",
        "        root_dir: path to 2017/\n",
        "        split: 'train' or 'test'\n",
        "        \"\"\"\n",
        "        csv_dir = os.path.join(root_dir, split)\n",
        "        csvs = glob.glob(os.path.join(csv_dir, \"*.csv\"))\n",
        "        assert len(csvs) > 0, f\"No CSV files found in {csv_dir}\"\n",
        "\n",
        "        df = pd.concat([pd.read_csv(c) for c in csvs], ignore_index=True)\n",
        "\n",
        "        self.classes = sorted(df[\"Label\"].unique())\n",
        "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
        "\n",
        "        self.x = df.drop(columns=[\"Label\"]).values.astype(np.float32)\n",
        "        self.y = np.array(\n",
        "            [self.class_to_idx[l] for l in df[\"Label\"]],\n",
        "            dtype=np.int64\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.x[idx]), torch.tensor(self.y[idx])"
      ],
      "id": "nGoN76koTgID"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d0BVvGMTgID"
      },
      "source": [
        "## Task builder"
      ],
      "id": "-d0BVvGMTgID"
    },
    {
      "cell_type": "code",
      "source": [
        "class RemappedSubset(Dataset):\n",
        "    \"\"\"\n",
        "    Subset that remaps global class indices to [0..C-1]\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, indices, class_ids):\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "        self.class_map = {cid: i for i, cid in enumerate(class_ids)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.dataset[self.indices[idx]]\n",
        "        return x, torch.tensor(self.class_map[y.item()])\n"
      ],
      "metadata": {
        "id": "dc-LvNYbWDtQ"
      },
      "id": "dc-LvNYbWDtQ",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dKlk2M2WTgID"
      },
      "outputs": [],
      "source": [
        "def build_task(dataset, class_names):\n",
        "    class_ids = [dataset.class_to_idx[c] for c in class_names]\n",
        "    idxs = np.where(np.isin(dataset.y, class_ids))[0]\n",
        "    return RemappedSubset(dataset, idxs, class_ids)"
      ],
      "id": "dKlk2M2WTgID"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyLmpf46TgID"
      },
      "source": [
        "## Model"
      ],
      "id": "gyLmpf46TgID"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MD8KacN6TgID"
      },
      "outputs": [],
      "source": [
        "class CILModel(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.fe = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.classifier = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.fe(x)\n",
        "        return self.classifier(z)\n",
        "\n",
        "    def expand_classes(self, n_new):\n",
        "        old = self.classifier\n",
        "        new = nn.Linear(old.in_features, old.out_features + n_new).to(device)\n",
        "        new.weight.data[:old.out_features] = old.weight.data\n",
        "        new.bias.data[:old.out_features] = old.bias.data\n",
        "        self.classifier = new"
      ],
      "id": "MD8KacN6TgID"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzKe9gvYTgID"
      },
      "source": [
        "## Replay Buffer (DER++)"
      ],
      "id": "fzKe9gvYTgID"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QV41fmpmTgIE"
      },
      "outputs": [],
      "source": [
        "class ReservoirBuffer:\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "        self.n_seen = 0\n",
        "        self.x, self.y, self.logits = [], [], []\n",
        "\n",
        "    def add(self, x, y, logits):\n",
        "        for xi, yi, li in zip(x, y, logits):\n",
        "            li = li.detach().cpu()\n",
        "            if len(self.x) < self.size:\n",
        "                self.x.append(xi.cpu())\n",
        "                self.y.append(yi.cpu())\n",
        "                self.logits.append(li)\n",
        "            else:\n",
        "                j = np.random.randint(0, self.n_seen + 1)\n",
        "                if j < self.size:\n",
        "                    self.x[j] = xi.cpu()\n",
        "                    self.y[j] = yi.cpu()\n",
        "                    self.logits[j] = li\n",
        "            self.n_seen += 1\n",
        "\n",
        "    def sample(self, batch_size, current_dim):\n",
        "        if len(self.x) == 0:\n",
        "            return None\n",
        "\n",
        "        idx = np.random.choice(len(self.x), min(batch_size, len(self.x)), replace=False)\n",
        "\n",
        "        bx = torch.stack([self.x[i] for i in idx]).to(device)\n",
        "        by = torch.stack([self.y[i] for i in idx]).to(device)\n",
        "\n",
        "        # PAD LOGITS\n",
        "        padded_logits = []\n",
        "        for i in idx:\n",
        "            old_logit = self.logits[i]\n",
        "            if old_logit.numel() < current_dim:\n",
        "                pad = torch.zeros(current_dim - old_logit.numel())\n",
        "                old_logit = torch.cat([old_logit, pad])\n",
        "            padded_logits.append(old_logit)\n",
        "\n",
        "        blogits = torch.stack(padded_logits).to(device)\n",
        "\n",
        "        return bx, by, blogits"
      ],
      "id": "QV41fmpmTgIE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUKM5dMBTgIE"
      },
      "source": [
        "## DER++ Training Loop"
      ],
      "id": "HUKM5dMBTgIE"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Q0yY9tpjTgIE"
      },
      "outputs": [],
      "source": [
        "def train_task(model, loader, buffer, optimizer, alpha=0.5, beta=0.5, epochs=1):\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            out = model(x)\n",
        "            loss = ce(out, y)\n",
        "\n",
        "            buf = buffer.sample(len(x), model.classifier.out_features)\n",
        "            if buf:\n",
        "                bx, by, blog = buf\n",
        "                loss += alpha * F.mse_loss(model(bx), blog)\n",
        "                loss += beta * ce(model(bx), by)\n",
        "\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            buffer.add(x, y, out.detach())"
      ],
      "id": "Q0yY9tpjTgIE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmG72ZZQTgIE"
      },
      "source": [
        "## Run Experiment"
      ],
      "id": "gmG72ZZQTgIE"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "cc5f7872",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc5f7872",
        "outputId": "f4c26f96-d027-4928-fbe1-d691a8708a6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  cil-intrusion-detection/data/processed/2017.zip\n",
            "replace 2017/train/portscan.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!unzip cil-intrusion-detection/data/processed/2017.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU852nUOTgIE",
        "outputId": "8fcb476a-bc27-49cd-b1c3-4d6d4e26347a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Task 0: ['benign']\n",
            "Test accuracy (seen classes): 1.0000\n",
            "\n",
            "=== Task 1: ['dos']\n",
            "Test accuracy (seen classes): 0.6349\n",
            "\n",
            "=== Task 2: ['ddos']\n",
            "Test accuracy (seen classes): 0.5512\n",
            "\n",
            "=== Task 3: ['portscan']\n",
            "Test accuracy (seen classes): 0.6163\n",
            "\n",
            "=== Task 4: ['ssh-patator']\n",
            "Test accuracy (seen classes): 0.6165\n",
            "\n",
            "=== Task 5: ['ftp-patator']\n",
            "Test accuracy (seen classes): 0.6160\n",
            "\n",
            "=== Task 6: ['web-attack']\n",
            "Test accuracy (seen classes): 0.6053\n",
            "\n",
            "=== Task 7: ['bot']\n",
            "Test accuracy (seen classes): 0.6261\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Paths\n",
        "DATA_ROOT = \"2017\"  # <-- folder created by unzip\n",
        "\n",
        "# Datasets\n",
        "train_dataset = IDSBaseDataset(DATA_ROOT, split=\"train\")\n",
        "test_dataset  = IDSBaseDataset(DATA_ROOT, split=\"test\")\n",
        "\n",
        "input_dim = train_dataset.x.shape[1]\n",
        "\n",
        "# Task definition (example)\n",
        "tasks = [\n",
        "    [\"benign\"],\n",
        "    [\"dos\"],\n",
        "    [\"ddos\"],\n",
        "    [\"portscan\"],\n",
        "    [\"ssh-patator\"],\n",
        "    [\"ftp-patator\"],\n",
        "    [\"web-attack\"],\n",
        "    [\"bot\"]\n",
        "]\n",
        "\n",
        "# Model + buffer\n",
        "model = CILModel(input_dim, len(tasks[0])).to(device)\n",
        "buffer = ReservoirBuffer(size=2000)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "seen_classes = []\n",
        "\n",
        "def evaluate(model, dataset, classes):\n",
        "    model.eval()\n",
        "    loader = DataLoader(build_task(dataset, classes), batch_size=256)\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            preds = model(x).argmax(1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return correct / total if total > 0 else 0\n",
        "\n",
        "\n",
        "for task_id, task_classes in enumerate(tasks):\n",
        "    print(f\"\\n=== Task {task_id}: {task_classes}\")\n",
        "\n",
        "    if task_id > 0:\n",
        "        model.expand_classes(len(task_classes))\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    seen_classes += task_classes\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        build_task(train_dataset, seen_classes),\n",
        "        batch_size=128,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    train_task(\n",
        "        model,\n",
        "        train_loader,\n",
        "        buffer,\n",
        "        optimizer,\n",
        "        alpha=0.5,\n",
        "        beta=0.5,\n",
        "        epochs=1\n",
        "    )\n",
        "\n",
        "    acc = evaluate(model, test_dataset, seen_classes)\n",
        "    print(f\"Test accuracy (seen classes): {acc:.4f}\")\n"
      ],
      "id": "wU852nUOTgIE"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}