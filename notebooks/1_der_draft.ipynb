{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esthy13/cil-intrusion-detection/blob/main/der_draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NkCuth4CTgIB",
      "metadata": {
        "id": "NkCuth4CTgIB"
      },
      "source": [
        "# DER++ for Intrusion Detection (CIC-IDS)\n",
        "\n",
        "Minimal **working** implementation of **Dark Experience Replay++**\n",
        "for class-incremental intrusion detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "383d2c74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "383d2c74",
        "outputId": "2a8870ca-f6fa-4e0a-9282-651909ddc447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'cil-intrusion-detection' already exists and is not an empty directory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/cil-intrusion-detection\n",
            "Already up to date.\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/esthy13/cil-intrusion-detection\n",
        "%cd cil-intrusion-detection\n",
        "!git pull\n",
        "# resetting the path to content to avoid issues in the rest of the notebook\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "EOVxYZQ2TgID",
      "metadata": {
        "id": "EOVxYZQ2TgID"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RDA-qUhCTgID",
      "metadata": {
        "id": "RDA-qUhCTgID"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "nGoN76koTgID",
      "metadata": {
        "id": "nGoN76koTgID"
      },
      "outputs": [],
      "source": [
        "class IDSBaseDataset(Dataset):\n",
        "    def __init__(self, root_dir, split=\"train\"):\n",
        "        \"\"\"\n",
        "        root_dir: path to 2017/\n",
        "        split: 'train' or 'test'\n",
        "        \"\"\"\n",
        "        csv_dir = os.path.join(root_dir, split)\n",
        "        csvs = glob.glob(os.path.join(csv_dir, \"*.csv\"))\n",
        "        assert len(csvs) > 0, f\"No CSV files found in {csv_dir}\"\n",
        "\n",
        "        df = pd.concat([pd.read_csv(c) for c in csvs], ignore_index=True)\n",
        "\n",
        "        labels = list(df[\"Label\"].unique())\n",
        "\n",
        "        if \"benign\" not in labels:\n",
        "            raise ValueError(\"Dataset must contain a 'benign' class\")\n",
        "\n",
        "        # Enforcing benign as class 0\n",
        "        labels = [\"benign\"] + sorted([l for l in labels if l != \"benign\"])\n",
        "\n",
        "        self.classes = labels\n",
        "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
        "\n",
        "        self.x = df.drop(columns=[\"Label\"]).values.astype(np.float32)\n",
        "        self.y = np.array(\n",
        "            [self.class_to_idx[label] for label in df[\"Label\"]],\n",
        "            dtype=np.int64\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.x[idx]), torch.tensor(self.y[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-d0BVvGMTgID",
      "metadata": {
        "id": "-d0BVvGMTgID"
      },
      "source": [
        "## Task builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "dc-LvNYbWDtQ",
      "metadata": {
        "id": "dc-LvNYbWDtQ"
      },
      "outputs": [],
      "source": [
        "class RemappedSubset(Dataset):\n",
        "    \"\"\"\n",
        "    Subset that remaps global class indices to [0..C-1]\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, indices, class_ids):\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "        self.class_map = {cid: i for i, cid in enumerate(class_ids)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.dataset[self.indices[idx]]\n",
        "        return x, torch.tensor(self.class_map[y.item()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "a58aa056",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_task(dataset, class_names):\n",
        "    class_ids = [dataset.class_to_idx[c] for c in class_names]\n",
        "    idxs = np.where(np.isin(dataset.y, class_ids))[0]\n",
        "    return RemappedSubset(dataset, idxs, class_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "dKlk2M2WTgID",
      "metadata": {
        "id": "dKlk2M2WTgID"
      },
      "outputs": [],
      "source": [
        "def build_scenario( all_classes, attacks_pattern, benign_class=\"benign\"):\n",
        "    \"\"\"\n",
        "    all_classes: ordered list of class names (benign must be first)\n",
        "    attacks_pattern: list of ints, number of NEW attacks per task\n",
        "                     e.g. [1,1,1] or [3,2] or [5]\n",
        "    benign_class: name of benign class (default: 'benign')\n",
        "\n",
        "    Returns:\n",
        "        tasks: list of lists of class names (cumulative)\n",
        "    \"\"\"\n",
        "\n",
        "    if benign_class not in all_classes:\n",
        "        raise ValueError(f\"Benign class '{benign_class}' not found in classes\")\n",
        "\n",
        "    if all_classes[0] != benign_class:\n",
        "        raise ValueError(\n",
        "            f\"Benign class must be index 0, got {all_classes[0]}\"\n",
        "        )\n",
        "\n",
        "    attack_classes = [c for c in all_classes if c != benign_class]\n",
        "\n",
        "    if sum(attacks_pattern) != len(attack_classes):\n",
        "        raise ValueError(\n",
        "            f\"Invalid attacks_pattern: sum={sum(attacks_pattern)}, \"\n",
        "            f\"but there are {len(attack_classes)} attack classes\"\n",
        "        )\n",
        "\n",
        "    tasks = []\n",
        "    current_index = 0\n",
        "\n",
        "    for _, n_new in enumerate(attacks_pattern):\n",
        "        current_index += n_new\n",
        "        seen_attacks = attack_classes[:current_index]\n",
        "        seen_classes = [benign_class] + seen_attacks\n",
        "        tasks.append(seen_classes)\n",
        "\n",
        "    return tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gyLmpf46TgID",
      "metadata": {
        "id": "gyLmpf46TgID"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "MD8KacN6TgID",
      "metadata": {
        "id": "MD8KacN6TgID"
      },
      "outputs": [],
      "source": [
        "class CILModel(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.fe = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.classifier = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.fe(x)\n",
        "        return self.classifier(z)\n",
        "\n",
        "    def expand_classes(self, n_new):\n",
        "        old = self.classifier\n",
        "        new = nn.Linear(old.in_features, old.out_features + n_new).to(device)\n",
        "        new.weight.data[:old.out_features] = old.weight.data\n",
        "        new.bias.data[:old.out_features] = old.bias.data\n",
        "        self.classifier = new"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fzKe9gvYTgID",
      "metadata": {
        "id": "fzKe9gvYTgID"
      },
      "source": [
        "## Replay Buffer (DER++)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "QV41fmpmTgIE",
      "metadata": {
        "id": "QV41fmpmTgIE"
      },
      "outputs": [],
      "source": [
        "class ReservoirBuffer:\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "        self.n_seen = 0\n",
        "        self.x, self.y, self.logits = [], [], []\n",
        "\n",
        "    def add(self, x, y, logits):\n",
        "        for xi, yi, li in zip(x, y, logits):\n",
        "            li = li.detach().cpu()\n",
        "            if len(self.x) < self.size:\n",
        "                self.x.append(xi.cpu())\n",
        "                self.y.append(yi.cpu())\n",
        "                self.logits.append(li)\n",
        "            else:\n",
        "                j = np.random.randint(0, self.n_seen + 1)\n",
        "                if j < self.size:\n",
        "                    self.x[j] = xi.cpu()\n",
        "                    self.y[j] = yi.cpu()\n",
        "                    self.logits[j] = li\n",
        "            self.n_seen += 1\n",
        "\n",
        "    def sample(self, batch_size, current_dim):\n",
        "        if len(self.x) == 0:\n",
        "            return None\n",
        "\n",
        "        idx = np.random.choice(len(self.x), min(batch_size, len(self.x)), replace=False)\n",
        "\n",
        "        bx = torch.stack([self.x[i] for i in idx]).to(device)\n",
        "        by = torch.stack([self.y[i] for i in idx]).to(device)\n",
        "\n",
        "        # PAD LOGITS\n",
        "        padded_logits = []\n",
        "        for i in idx:\n",
        "            old_logit = self.logits[i]\n",
        "            if old_logit.numel() < current_dim:\n",
        "                pad = torch.zeros(current_dim - old_logit.numel())\n",
        "                old_logit = torch.cat([old_logit, pad])\n",
        "            padded_logits.append(old_logit)\n",
        "\n",
        "        blogits = torch.stack(padded_logits).to(device)\n",
        "\n",
        "        return bx, by, blogits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HUKM5dMBTgIE",
      "metadata": {
        "id": "HUKM5dMBTgIE"
      },
      "source": [
        "## DER++ Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "Q0yY9tpjTgIE",
      "metadata": {
        "id": "Q0yY9tpjTgIE"
      },
      "outputs": [],
      "source": [
        "def train_task(model, loader, buffer, optimizer, alpha=0.5, beta=0.5, epochs=1):\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            out = model(x)\n",
        "            loss = ce(out, y)\n",
        "\n",
        "            buf = buffer.sample(len(x), model.classifier.out_features)\n",
        "            if buf:\n",
        "                bx, by, blog = buf\n",
        "                loss += alpha * F.mse_loss(model(bx), blog)\n",
        "                loss += beta * ce(model(bx), by)\n",
        "\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            buffer.add(x, y, out.detach())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "63021c53",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, dataset, seen_classes):\n",
        "    model.eval()\n",
        "\n",
        "    eval_dataset = build_task(dataset, seen_classes)\n",
        "    loader = DataLoader(eval_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "    all_preds, all_targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            preds = model(x).argmax(1).cpu().numpy()\n",
        "\n",
        "            all_preds.append(preds)\n",
        "            all_targets.append(y.numpy())\n",
        "\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_targets = np.concatenate(all_targets)\n",
        "\n",
        "    acc = accuracy_score(all_targets, all_preds)\n",
        "    f1  = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "\n",
        "    return acc, f1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gmG72ZZQTgIE",
      "metadata": {
        "id": "gmG72ZZQTgIE"
      },
      "source": [
        "## Run Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "cc5f7872",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc5f7872",
        "outputId": "f4c26f96-d027-4928-fbe1-d691a8708a6a"
      },
      "outputs": [],
      "source": [
        "# !unzip cil-intrusion-detection/data/processed/2017.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "wU852nUOTgIE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU852nUOTgIE",
        "outputId": "8fcb476a-bc27-49cd-b1c3-4d6d4e26347a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'benign': 0, 'bot': 1, 'ddos': 2, 'dos': 3, 'ftp-patator': 4, 'portscan': 5, 'ssh-patator': 6, 'web-attack': 7}\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "DATA_ROOT = \"2017\"  # <-- folder created by unzip\n",
        "\n",
        "# Datasets\n",
        "train_dataset = IDSBaseDataset(DATA_ROOT, split=\"train\")\n",
        "test_dataset  = IDSBaseDataset(DATA_ROOT, split=\"test\")\n",
        "\n",
        "print(train_dataset.class_to_idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "f7ae59f6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Scenario 1 ===\n",
            "\n",
            "=== Task 0: ['benign', 'dos']\n",
            "Accuracy: 0.7781 | Macro-F1: 0.4563\n",
            "\n",
            "=== Task 1: ['benign', 'dos', 'ddos']\n",
            "Accuracy: 0.8287 | Macro-F1: 0.3136\n",
            "\n",
            "=== Task 2: ['benign', 'dos', 'ddos', 'portscan']\n",
            "Accuracy: 0.7812 | Macro-F1: 0.2291\n",
            "\n",
            "=== Task 3: ['benign', 'dos', 'ddos', 'portscan', 'ssh-patator']\n",
            "Accuracy: 0.7856 | Macro-F1: 0.2568\n",
            "\n",
            "=== Task 4: ['benign', 'dos', 'ddos', 'portscan', 'ssh-patator', 'ftp-patator']\n",
            "Accuracy: 0.7791 | Macro-F1: 0.2146\n",
            "\n",
            "=== Task 5: ['benign', 'dos', 'ddos', 'portscan', 'ssh-patator', 'ftp-patator', 'web-attack']\n",
            "Accuracy: 0.7764 | Macro-F1: 0.1295\n",
            "\n",
            "=== Task 6: ['benign', 'dos', 'ddos', 'portscan', 'ssh-patator', 'ftp-patator', 'web-attack', 'bot']\n",
            "Accuracy: 0.7806 | Macro-F1: 0.1148\n",
            "\n",
            "=== Scenario 2 ===\n",
            "\n",
            "=== Task 0: ['benign', 'dos', 'ddos', 'portscan', 'ssh-patator']\n",
            "Accuracy: 0.1934 | Macro-F1: 0.1179\n",
            "\n",
            "=== Task 1: ['benign', 'dos', 'ddos', 'portscan', 'ssh-patator', 'ftp-patator', 'web-attack', 'bot']\n",
            "Accuracy: 0.1950 | Macro-F1: 0.0695\n",
            "\n",
            "=== Scenario 3 ===\n",
            "\n",
            "=== Task 0: ['benign', 'dos']\n",
            "Accuracy: 0.8871 | Macro-F1: 0.4702\n",
            "\n",
            "=== Task 1: ['benign', 'dos', 'ddos', 'portscan', 'ssh-patator']\n",
            "Accuracy: 0.3594 | Macro-F1: 0.1436\n",
            "\n",
            "=== Task 2: ['benign', 'dos', 'ddos', 'portscan', 'ssh-patator', 'ftp-patator', 'web-attack', 'bot']\n",
            "Accuracy: 0.3518 | Macro-F1: 0.0894\n"
          ]
        }
      ],
      "source": [
        "input_dim = train_dataset.x.shape[1]\n",
        "\n",
        "# Task definition (example)\n",
        "all_classes = [\n",
        "    \"benign\",\n",
        "    \"dos\",\n",
        "    \"ddos\",\n",
        "    \"portscan\",\n",
        "    \"ssh-patator\",\n",
        "    \"ftp-patator\",\n",
        "    \"web-attack\",\n",
        "    \"bot\"\n",
        "]\n",
        "\n",
        "# Scenario A: 1+1+1+1+1+1+1+1\n",
        "scenario_1 = build_scenario(all_classes, [1,1,1,1,1,1,1])\n",
        "\n",
        "# Scenario B: 5+3\n",
        "scenario_2 = build_scenario(all_classes, [4, 3])\n",
        "\n",
        "# Scenario C: 2+3+3\n",
        "scenario_3 = build_scenario(all_classes, [1, 3, 3])\n",
        "\n",
        "for scenario_id, tasks in enumerate([scenario_1, scenario_2, scenario_3]):\n",
        "    print(f\"\\n=== Scenario {scenario_id+1} ===\")\n",
        "    model = CILModel(input_dim, len(tasks[0])).to(device)\n",
        "    buffer = ReservoirBuffer(size=2000)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    for task_id, seen_classes in enumerate(tasks):\n",
        "        print(f\"\\n=== Task {task_id}: {seen_classes}\")\n",
        "\n",
        "        if task_id > 0:\n",
        "            n_new = len(tasks[task_id]) - len(tasks[task_id-1])\n",
        "            model.expand_classes(n_new)\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            build_task(train_dataset, seen_classes),\n",
        "            batch_size=128,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        train_task(model, train_loader, buffer, optimizer)\n",
        "\n",
        "        acc, f1 = evaluate(model, test_dataset, seen_classes)\n",
        "        print(f\"Accuracy: {acc:.4f} | Macro-F1: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3272f3ae",
      "metadata": {},
      "source": [
        "**Scenario 1** does not perform well the model fails to learn the new classes\n",
        "**Scenario 2** and **Scenario 3** macro f1 score gets better with more classes which means that the model is working better"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
