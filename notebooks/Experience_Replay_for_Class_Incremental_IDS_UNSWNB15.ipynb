{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93cJzwaWmv6I"
      },
      "outputs": [],
      "source": [
        "# ER (Experience Replay) â€” UNSW-NB15 Continual Learning Baseline\n",
        "\n",
        "Goal: Implement Experience Replay (ER) for a class-incremental IDS scenario on UNSW-NB15.\n",
        "Training  tasks where attack classes appear progressively, while Normal traffic is always present.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ðŸ”¹1. Problem Setting**\n",
        "\n",
        "this is to simulate a class incremental learning scenario for IDS using the UNSW-NB15 dataset. The goal is to study catastrophic forgetting when new attack classes are introduced over time.\n",
        "example:\n",
        "\n",
        "Task 1 â†’ Normal + Generic\n",
        "\n",
        "Task 2 â†’ Normal + Generic + Exploits\n",
        "\n",
        "Normal traffic is always present\n",
        "\n",
        "\n",
        "matches real IDS evolution. Goal:\n",
        "Evaluate whether Experience Replay reduces forgetting when new attack\n",
        "classes are introduced.**bold text**"
      ],
      "metadata": {
        "id": "dFedO4ZA3hZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Imports =====\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "import random\n",
        "\n",
        "# ===== Device =====\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAWkoLre47B3",
        "outputId": "302ca194-3312-4ae5-9620-685ce34447c9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Dataset Loading\n",
        "The dataset contains 45 columns, including:\n",
        "- Flow-based numerical features (e.g., duration, packets, bytes)\n",
        "- Categorical protocol-related features (proto, service, state)\n",
        "- Two label columns:\n",
        "    - `attack_cat` (multi-class attack category)\n",
        "    - `label` (binary normal vs attack)\n",
        "\n",
        "For our class-incremental learning setup, i will use `attack_cat`\n",
        "as the target label."
      ],
      "metadata": {
        "id": "qA79qN_l548z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "train = pd.read_csv(\"UNSW_NB15_training-set.csv\")\n",
        "test  = pd.read_csv(\"UNSW_NB15_testing-set.csv\")\n",
        "\n",
        "print(\"Train shape:\", train.shape)\n",
        "print(\"Test shape:\", test.shape)\n",
        "\n",
        "train.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "J5Qcv6dDofvp",
        "outputId": "c0cd03fa-5663-4a9b-88d9-4917986b33ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (175341, 45)\n",
            "Test shape: (82332, 45)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id       dur proto service state  spkts  dpkts  sbytes  dbytes       rate  \\\n",
              "0   1  0.121478   tcp       -   FIN      6      4     258     172  74.087490   \n",
              "1   2  0.649902   tcp       -   FIN     14     38     734   42014  78.473372   \n",
              "2   3  1.623129   tcp       -   FIN      8     16     364   13186  14.170161   \n",
              "3   4  1.681642   tcp     ftp   FIN     12     12     628     770  13.677108   \n",
              "4   5  0.449454   tcp       -   FIN     10      6     534     268  33.373826   \n",
              "\n",
              "   ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  ct_ftp_cmd  \\\n",
              "0  ...                 1               1             0           0   \n",
              "1  ...                 1               2             0           0   \n",
              "2  ...                 1               3             0           0   \n",
              "3  ...                 1               3             1           1   \n",
              "4  ...                 1              40             0           0   \n",
              "\n",
              "   ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  attack_cat  \\\n",
              "0                 0           1           1                0      Normal   \n",
              "1                 0           1           6                0      Normal   \n",
              "2                 0           2           6                0      Normal   \n",
              "3                 0           2           1                0      Normal   \n",
              "4                 0           2          39                0      Normal   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  \n",
              "3      0  \n",
              "4      0  \n",
              "\n",
              "[5 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-165f2766-a15f-4d67-b22c-d5b926390675\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dur</th>\n",
              "      <th>proto</th>\n",
              "      <th>service</th>\n",
              "      <th>state</th>\n",
              "      <th>spkts</th>\n",
              "      <th>dpkts</th>\n",
              "      <th>sbytes</th>\n",
              "      <th>dbytes</th>\n",
              "      <th>rate</th>\n",
              "      <th>...</th>\n",
              "      <th>ct_dst_sport_ltm</th>\n",
              "      <th>ct_dst_src_ltm</th>\n",
              "      <th>is_ftp_login</th>\n",
              "      <th>ct_ftp_cmd</th>\n",
              "      <th>ct_flw_http_mthd</th>\n",
              "      <th>ct_src_ltm</th>\n",
              "      <th>ct_srv_dst</th>\n",
              "      <th>is_sm_ips_ports</th>\n",
              "      <th>attack_cat</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.121478</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>258</td>\n",
              "      <td>172</td>\n",
              "      <td>74.087490</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.649902</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>14</td>\n",
              "      <td>38</td>\n",
              "      <td>734</td>\n",
              "      <td>42014</td>\n",
              "      <td>78.473372</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.623129</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>364</td>\n",
              "      <td>13186</td>\n",
              "      <td>14.170161</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.681642</td>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp</td>\n",
              "      <td>FIN</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>628</td>\n",
              "      <td>770</td>\n",
              "      <td>13.677108</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.449454</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>534</td>\n",
              "      <td>268</td>\n",
              "      <td>33.373826</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 45 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-165f2766-a15f-4d67-b22c-d5b926390675')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-165f2766-a15f-4d67-b22c-d5b926390675 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-165f2766-a15f-4d67-b22c-d5b926390675');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Class-Incremental Task Scenario Definition\n",
        "\n",
        "To simulate a realistic evolving threat environment, defining\n",
        "a class-incremental learning (CIL) scenario.\n",
        "\n",
        "- Task 1: The model is trained on Normal + Generic traffic.\n",
        "- Task 2: A new attack class (Exploits) is introduced,\n",
        "  while previously seen classes remain present.\n",
        "\n",
        "This setup mimics real-world IDS deployment, where new attack\n",
        "types appear over time and the model must adapt without\n",
        "forgetting previously learned patterns.\n"
      ],
      "metadata": {
        "id": "-zFqcm0p69WZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task scenario (using the exmaple i mentioned )\n",
        "NORMAL = \"Normal\"\n",
        "attack_order = [\"Generic\", \"Exploits\", \"Fuzzers\", \"DoS\", \"Reconnaissance\", \"Analysis\", \"Backdoor\", \"Shellcode\", \"Worms\"]\n",
        "\n",
        "# just an exmaple: Task1 -> Task2\n",
        "scenario_1plus1 = [\n",
        "    [NORMAL, \"Generic\"],                 # Task 1 classes\n",
        "    [NORMAL, \"Generic\", \"Exploits\"],     # Task 2 classes\n",
        "]\n",
        "\n",
        "#The build_task_df function filters the dataset to include only the classes available at a given task.\n",
        "\n",
        "def build_task_df(df, classes):\n",
        "    \"\"\"Filter dataframe to only the given attack_cat classes.\"\"\"\n",
        "    return df[df[\"attack_cat\"].isin(classes)].copy()\n",
        "\n",
        "# Build task datasets\n",
        "task1_train = build_task_df(train, scenario_1plus1[0])\n",
        "task1_test  = build_task_df(test,  scenario_1plus1[0])\n",
        "\n",
        "task2_train = build_task_df(train, scenario_1plus1[1])\n",
        "task2_test  = build_task_df(test,  scenario_1plus1[1])\n",
        "\n",
        "print(\"Task 1 train shape:\", task1_train.shape)\n",
        "print(\"Task 1 test shape: \", task1_test.shape)\n",
        "print(\"Task 2 train shape:\", task2_train.shape)\n",
        "print(\"Task 2 test shape: \", task2_test.shape)\n",
        "\n",
        "print(\"\\nTask 1 class counts:\\n\", task1_train[\"attack_cat\"].value_counts())\n",
        "print(\"\\nTask 2 class counts:\\n\", task2_train[\"attack_cat\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI9aV9Bxm13G",
        "outputId": "6fcd2ea8-0a03-416a-a19f-68e7eb0c9109"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1 train shape: (96000, 45)\n",
            "Task 1 test shape:  (55871, 45)\n",
            "Task 2 train shape: (129393, 45)\n",
            "Task 2 test shape:  (67003, 45)\n",
            "\n",
            "Task 1 class counts:\n",
            " attack_cat\n",
            "Normal     56000\n",
            "Generic    40000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Task 2 class counts:\n",
            " attack_cat\n",
            "Normal      56000\n",
            "Generic     40000\n",
            "Exploits    33393\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Feature Selection**\n",
        "\n",
        "I  removed non-feature columns (id, attack_cat, label), and separated categorical and numerical features.\n",
        "\n",
        "Before training the model, separate input features from labels.\n",
        "\n",
        "removing:\n",
        "- `id` â†’ Identifier (not informative for learning)\n",
        "- `attack_cat` â†’ Multi-class label (used as target)\n",
        "- `label` â†’ Binary label (not used in this multi-class CIL setup)\n",
        "\n",
        "The remaining columns form the feature space used by the model.\n",
        "\n",
        "removing the non-informative or target columns. The model should only see feature values, not labels or identifiers. This leaves us with 42 raw features.\n",
        "Why drop the binary label?\n",
        "Because we are solving a multi-class incremental problem using attack_cat, not binary classification."
      ],
      "metadata": {
        "id": "bmaua8T04NaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#After removing three columns from the original 45, we obtain 42 feature columns before encoding.\n",
        "# Columns to drop\n",
        "drop_cols = [\"id\", \"attack_cat\", \"label\"]\n",
        "\n",
        "feature_cols = [c for c in train.columns if c not in drop_cols]\n",
        "\n",
        "print(\"Number of feature columns:\", len(feature_cols))\n",
        "print(feature_cols[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sy7lOkSFpWB6",
        "outputId": "40271616-cd25-4402-91f4-bdf87feaeb65"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of feature columns: 42\n",
            "['dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Categorical columns present:\",\n",
        "      all(col in feature_cols for col in [\"proto\",\"service\",\"state\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE3-AyQKpqfX",
        "outputId": "e5eb17f9-1508-42e0-bbc7-0251c68ad344"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical columns present: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use a two-hidden-layer MLP for classification. The input dimension is 186 after preprocessing. The output layer size corresponds to the number of classes at each task. ReLU activations are used in hidden layers and raw logits are passed to CrossEntropyLoss."
      ],
      "metadata": {
        "id": "GOEka3TmKg5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MLPIDS(nn.Module):   #This is your Intrusion Detection Model. It is a simple Multi-Layer Perceptron (MLP)\n",
        "    def __init__(self, input_dim: int, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.out = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.out(x)\n",
        "\n",
        "model = MLPIDS(input_dim=input_dim, num_classes=num_classes_task1).to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tm1xTmHrDsZ",
        "outputId": "a396fd57-9c5d-43fe-adbd-5b33c606e0ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPIDS(\n",
            "  (fc1): Linear(in_features=186, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "le1 = LabelEncoder()\n",
        "le1.fit(task1_train[\"attack_cat\"])\n",
        "\n",
        "y1_train = le1.transform(task1_train[\"attack_cat\"])\n",
        "y1_test  = le1.transform(task1_test[\"attack_cat\"])\n",
        "\n",
        "print(\"Task1 classes:\", list(le1.classes_))\n",
        "print(\"Unique y1 labels:\", np.unique(y1_train))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FO1FaJvtKWW",
        "outputId": "de223ef4-3b61-4cb1-e569-f573dc3dfee5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task1 classes: ['Generic', 'Normal']\n",
            "Unique y1 labels: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Feature Encoding and Scaling\n",
        " applying a preprocessing pipeline consisting of:\n",
        "\n",
        "- OneHotEncoder for categorical protocol-related features:\n",
        "  - `proto`\n",
        "  - `service`\n",
        "  - `state`\n",
        "\n",
        "- RobustScaler for numerical features.\n",
        "\n",
        "RobustScaler is chosen because network traffic features are often\n",
        "heavy tailed and contains extreme values. It is more stable than\n",
        "StandardScaler in this context.\n",
        "\n",
        "To preserve class incremental learning realism, the preprocessing\n",
        "pipeline is fitted only on Task 1 training data.\n"
      ],
      "metadata": {
        "id": "hgzEKgH--QyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "categorical_cols = [\"proto\", \"service\", \"state\"]\n",
        "drop_cols = [\"id\", \"attack_cat\", \"label\"]\n",
        "feature_cols = [c for c in train.columns if c not in drop_cols]\n",
        "numeric_cols = [c for c in feature_cols if c not in categorical_cols]\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
        "        (\"num\", RobustScaler(), numeric_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor.fit(task1_train[feature_cols])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "KJPoC3d8u_Wk",
        "outputId": "a7246c4a-9df3-4eac-8a5f-0ff743045d56"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore'),\n",
              "                                 ['proto', 'service', 'state']),\n",
              "                                ('num', RobustScaler(),\n",
              "                                 ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes',\n",
              "                                  'rate', 'sttl', 'dttl', 'sload', 'dload',\n",
              "                                  'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit',\n",
              "                                  'djit', 'swin', 'stcpb', 'dtcpb', 'dwin',\n",
              "                                  'tcprtt', 'synack', 'ackdat', 'smean',\n",
              "                                  'dmean', 'trans_depth', 'response_body_len',\n",
              "                                  'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', ...])])"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â–¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â–¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;proto&#x27;, &#x27;service&#x27;, &#x27;state&#x27;]),\n",
              "                                (&#x27;num&#x27;, RobustScaler(),\n",
              "                                 [&#x27;dur&#x27;, &#x27;spkts&#x27;, &#x27;dpkts&#x27;, &#x27;sbytes&#x27;, &#x27;dbytes&#x27;,\n",
              "                                  &#x27;rate&#x27;, &#x27;sttl&#x27;, &#x27;dttl&#x27;, &#x27;sload&#x27;, &#x27;dload&#x27;,\n",
              "                                  &#x27;sloss&#x27;, &#x27;dloss&#x27;, &#x27;sinpkt&#x27;, &#x27;dinpkt&#x27;, &#x27;sjit&#x27;,\n",
              "                                  &#x27;djit&#x27;, &#x27;swin&#x27;, &#x27;stcpb&#x27;, &#x27;dtcpb&#x27;, &#x27;dwin&#x27;,\n",
              "                                  &#x27;tcprtt&#x27;, &#x27;synack&#x27;, &#x27;ackdat&#x27;, &#x27;smean&#x27;,\n",
              "                                  &#x27;dmean&#x27;, &#x27;trans_depth&#x27;, &#x27;response_body_len&#x27;,\n",
              "                                  &#x27;ct_srv_src&#x27;, &#x27;ct_state_ttl&#x27;, &#x27;ct_dst_ltm&#x27;, ...])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;proto&#x27;, &#x27;service&#x27;, &#x27;state&#x27;]),\n",
              "                                (&#x27;num&#x27;, RobustScaler(),\n",
              "                                 [&#x27;dur&#x27;, &#x27;spkts&#x27;, &#x27;dpkts&#x27;, &#x27;sbytes&#x27;, &#x27;dbytes&#x27;,\n",
              "                                  &#x27;rate&#x27;, &#x27;sttl&#x27;, &#x27;dttl&#x27;, &#x27;sload&#x27;, &#x27;dload&#x27;,\n",
              "                                  &#x27;sloss&#x27;, &#x27;dloss&#x27;, &#x27;sinpkt&#x27;, &#x27;dinpkt&#x27;, &#x27;sjit&#x27;,\n",
              "                                  &#x27;djit&#x27;, &#x27;swin&#x27;, &#x27;stcpb&#x27;, &#x27;dtcpb&#x27;, &#x27;dwin&#x27;,\n",
              "                                  &#x27;tcprtt&#x27;, &#x27;synack&#x27;, &#x27;ackdat&#x27;, &#x27;smean&#x27;,\n",
              "                                  &#x27;dmean&#x27;, &#x27;trans_depth&#x27;, &#x27;response_body_len&#x27;,\n",
              "                                  &#x27;ct_srv_src&#x27;, &#x27;ct_state_ttl&#x27;, &#x27;ct_dst_ltm&#x27;, ...])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;proto&#x27;, &#x27;service&#x27;, &#x27;state&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;dur&#x27;, &#x27;spkts&#x27;, &#x27;dpkts&#x27;, &#x27;sbytes&#x27;, &#x27;dbytes&#x27;, &#x27;rate&#x27;, &#x27;sttl&#x27;, &#x27;dttl&#x27;, &#x27;sload&#x27;, &#x27;dload&#x27;, &#x27;sloss&#x27;, &#x27;dloss&#x27;, &#x27;sinpkt&#x27;, &#x27;dinpkt&#x27;, &#x27;sjit&#x27;, &#x27;djit&#x27;, &#x27;swin&#x27;, &#x27;stcpb&#x27;, &#x27;dtcpb&#x27;, &#x27;dwin&#x27;, &#x27;tcprtt&#x27;, &#x27;synack&#x27;, &#x27;ackdat&#x27;, &#x27;smean&#x27;, &#x27;dmean&#x27;, &#x27;trans_depth&#x27;, &#x27;response_body_len&#x27;, &#x27;ct_srv_src&#x27;, &#x27;ct_state_ttl&#x27;, &#x27;ct_dst_ltm&#x27;, &#x27;ct_src_dport_ltm&#x27;, &#x27;ct_dst_sport_ltm&#x27;, &#x27;ct_dst_src_ltm&#x27;, &#x27;is_ftp_login&#x27;, &#x27;ct_ftp_cmd&#x27;, &#x27;ct_flw_http_mthd&#x27;, &#x27;ct_src_ltm&#x27;, &#x27;ct_srv_dst&#x27;, &#x27;is_sm_ips_ports&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RobustScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.RobustScaler.html\">?<span>Documentation for RobustScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RobustScaler()</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Transform Task Data into Model Inputs\n",
        "\n",
        " applying the preprocessing pipeline to convert each task dataset into\n",
        "numerical model inputs.\n",
        "\n",
        "- The transformer output may be sparse (due to one-hot encoding),\n",
        "  so we convert it into a dense NumPy array for PyTorch.\n",
        "- We record the final input dimension (`input_dim`) which defines the\n",
        "  neural network input layer size.\n"
      ],
      "metadata": {
        "id": "uBNYrHB5-6ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def to_dense_array(X):\n",
        "    return X.toarray() if hasattr(X, \"toarray\") else np.asarray(X)\n",
        "\n",
        "X1_train_np = to_dense_array(preprocessor.transform(task1_train[feature_cols]))\n",
        "X1_test_np  = to_dense_array(preprocessor.transform(task1_test[feature_cols]))\n",
        "\n",
        "input_dim = X1_train_np.shape[1]\n",
        "print(\"Input dim:\", input_dim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNcRYWXKvDZw",
        "outputId": "6e8f91ac-d844-45c5-cef6-32ade2777626"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input dim: 186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Label Encoding for Task 1\n",
        "\n",
        "For Task 1, encode attack categories into integer labels\n",
        "using LabelEncoder.\n",
        "Since Task 1 contains only:\n",
        "- Generic\n",
        "- Normal\n",
        "the model output layer will initially have 2 classes.\n",
        "\n",
        "This mapping ensures that labels are in the range [0, C-1],\n",
        "which is required for CrossEntropyLoss in PyTorch.\n",
        "Why not use the same encoder for all tasks?\n",
        "\n",
        "Because at this stage the model has only seen Task1 classes. Later, when Task2 introduces a new class, we expand the classifier and update the mapping.\n"
      ],
      "metadata": {
        "id": "bZ7yh5OH_sbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "le1 = LabelEncoder()\n",
        "le1.fit(task1_train[\"attack_cat\"])\n",
        "\n",
        "y1_train = le1.transform(task1_train[\"attack_cat\"])\n",
        "y1_test  = le1.transform(task1_test[\"attack_cat\"])\n",
        "\n",
        "print(\"Task1 classes:\", list(le1.classes_))\n",
        "print(\"Counts:\", np.bincount(y1_train))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YykSxIivIDT",
        "outputId": "65c86199-e40f-4c69-aa7c-1250f7079e12"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task1 classes: ['Generic', 'Normal']\n",
            "Counts: [40000 56000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. PyTorch Dataset and DataLoader (Task 1)\n",
        "converting the preprocessed NumPy arrays into PyTorch tensors.\n",
        "- Features are stored as float32 tensors.\n",
        "- Labels are stored as long tensors (required for CrossEntropyLoss).\n",
        "\n",
        "then creating a\n",
        "- A training DataLoader (with shuffling)\n",
        "- A test DataLoader (without shuffling)\n",
        "\n",
        "Batch size is set to 256.\n"
      ],
      "metadata": {
        "id": "uOWiiBbTAkrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "train_ds1 = TensorDataset(\n",
        "    torch.tensor(X1_train_np, dtype=torch.float32),\n",
        "    torch.tensor(y1_train, dtype=torch.long)\n",
        ")\n",
        "test_ds1 = TensorDataset(\n",
        "    torch.tensor(X1_test_np, dtype=torch.float32),\n",
        "    torch.tensor(y1_test, dtype=torch.long)\n",
        ")\n",
        "\n",
        "train_loader1 = DataLoader(train_ds1, batch_size=batch_size, shuffle=True)\n",
        "test_loader1  = DataLoader(test_ds1, batch_size=batch_size, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "_IUKXpvMxEeR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Training Function (Task 1)\n",
        "\n",
        "defining a generic training function for a single task.\n",
        "\n",
        "Key components:\n",
        "- Optimizer: Adam\n",
        "- Loss function: CrossEntropyLoss\n",
        "- Class weighting to mitigate class imbalance\n",
        "- Evaluation using Accuracy and Macro-F1\n",
        "\n",
        "Class weights are computed from label frequencies to reduce bias\n",
        "towards dominant classes (e.g., Normal traffic).\n",
        "Why Macro-F1?\n",
        "\n",
        "Macro-F1 gives equal importance to all classes and is more appropriate for imbalanced multi-class problems\n"
      ],
      "metadata": {
        "id": "bF_k9rslBBTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def train_one_task(model, train_loader, test_loader, device, y_train_for_weights, epochs=3, lr=1e-4):\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Class weights to reduce imbalance bias\n",
        "    counts = np.bincount(y_train_for_weights)\n",
        "    weights = (counts.sum() / (len(counts) * counts)).astype(np.float32)\n",
        "    weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = loss_fn(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        acc, f1 = evaluate(model, test_loader, device)\n",
        "        print(f\"Epoch {epoch}/{epochs} | Loss: {avg_loss:.4f} | Test Acc: {acc:.4f} | Test Macro-F1: {f1:.4f}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Fa1e2XLWxIs6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Task 1 Training Results\n",
        "\n",
        " initialize the neural network with 2 output classes\n",
        "(Generic and Normal) and train on Task 1.\n",
        "\n",
        "After training, we evaluate performance on Task 1 test data\n",
        "using Accuracy and Macro-F1.\n"
      ],
      "metadata": {
        "id": "BmJczk4TBcBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLPIDS(input_dim=input_dim, num_classes=len(le1.classes_)).to(device)\n",
        "\n",
        "model = train_one_task(\n",
        "    model=model,\n",
        "    train_loader=train_loader1,\n",
        "    test_loader=test_loader1,\n",
        "    device=device,\n",
        "    y_train_for_weights=y1_train,\n",
        "    epochs=3,\n",
        "    lr=1e-4\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAl8rPjpxKuJ",
        "outputId": "025f2f00-4f9e-4a95-a859-b32aa7b646f4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 | Loss: 1.8928 | Test Acc: 0.9508 | Test Macro-F1: 0.9460\n",
            "Epoch 2/3 | Loss: 2.2059 | Test Acc: 0.9759 | Test Macro-F1: 0.9731\n",
            "Epoch 3/3 | Loss: 1.9823 | Test Acc: 0.9841 | Test Macro-F1: 0.9821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss\n",
        "\n",
        "CrossEntropyLoss (with class weights)\n",
        "\n",
        "Measures prediction error\n",
        "\n",
        "Lower is better\n",
        "\n",
        "Test Accuracy\n",
        ", Percentage of correctly classified samples\n",
        "\n",
        "reached ~98.4%- Model distinguishes Generic vs Normal very well.\n",
        "\n",
        "Macro-F1 = average of F1 for each class equally.\n",
        "\n",
        "Since Task1 has: Generic (40k), Normal (56k)\n",
        "\n",
        "Macro-F1 avoids bias toward the larger class.\n",
        "\n",
        "reached:\n",
        "\n",
        "â†’ 0.9821\n",
        "\n",
        "That means: Both classes are classified well,Model is not biased heavily toward one class"
      ],
      "metadata": {
        "id": "vc0dy-ACBx4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Task 2 WITHOUT ER (to observe forgetting )"
      ],
      "metadata": {
        "id": "zP5yaKswyQa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Task 2 Data Transformation\n",
        "\n",
        "Task 2 introduces a new attack class (Exploits) while keeping previously\n",
        "seen classes (Normal, Generic).\n",
        "\n",
        "We transform Task 2 using the SAME preprocessing pipeline fitted on Task 1.\n",
        "This avoids leaking information from future tasks into preprocessing and\n",
        "matches the continual learning setting.\n",
        "\n",
        "The output feature dimension remains 186 (same input space for all tasks).\n"
      ],
      "metadata": {
        "id": "BvxOXF27Cy6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Task2 (same preprocessor fitted on Task1)\n",
        "X2_train_np = to_dense_array(preprocessor.transform(task2_train[feature_cols]))\n",
        "X2_test_np  = to_dense_array(preprocessor.transform(task2_test[feature_cols]))\n",
        "\n",
        "print(\"Task2 X train shape:\", X2_train_np.shape)\n",
        "\n",
        "#Task2 has more samples because it includes an additional class (Exploits).\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oPpBbuiyVFE",
        "outputId": "75434369-672a-40a2-c40e-3b0a2baf6160"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task2 X train shape: (129393, 186)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Label Encoding for Task 2 (Expanded Class Set)\n",
        "\n",
        "Task 2 introduces a new class: Exploits.\n",
        "\n",
        "We create a new LabelEncoder that maps:\n",
        "- Exploits\n",
        "- Generic\n",
        "- Normal\n",
        "\n",
        "to integer labels in the range [0, 2].\n",
        "\n",
        "This reflects the expanded classification space for Task 2.\n"
      ],
      "metadata": {
        "id": "xDnaxj4aDNl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "#\n",
        "le2 = LabelEncoder()\n",
        "le2.fit(task2_train[\"attack_cat\"])\n",
        "\n",
        "y2_train = le2.transform(task2_train[\"attack_cat\"])\n",
        "y2_test  = le2.transform(task2_test[\"attack_cat\"])\n",
        "\n",
        "print(\"Task2 classes:\", list(le2.classes_))\n",
        "print(\"Unique y2 labels:\", np.unique(y2_train))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHOy_UQPyiTT",
        "outputId": "a50351d3-a0cd-4193-9063-dba1b1c40822"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task2 classes: ['Exploits', 'Generic', 'Normal']\n",
            "Unique y2 labels: [0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14. Expanding the Classifier for Incremental Learning\n",
        "\n",
        "When Task 2 introduces a new class, the model's output layer must expand\n",
        "from 2 classes to 3 classes.\n",
        "\n",
        "i defined a function that:\n",
        "\n",
        "1. Creates a new output layer with the updated number of classes.\n",
        "2. Copies the learned weights and biases from the old classes.\n",
        "3. Initializes the new class weights randomly.\n",
        "\n",
        "This allows the model to retain knowledge of previous classes\n",
        "while enabling learning of the new class.\n"
      ],
      "metadata": {
        "id": "749__NW5EMiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "def expand_output_layer(model, new_num_classes):\n",
        "    old_out = model.out\n",
        "    old_num_classes = old_out.out_features\n",
        "\n",
        "    if new_num_classes <= old_num_classes:\n",
        "        return model  # nothing to do\n",
        "\n",
        "    # New layer\n",
        "    new_out = nn.Linear(old_out.in_features, new_num_classes)\n",
        "\n",
        "    # Copy old weights/bias into first part\n",
        "    with torch.no_grad():\n",
        "        new_out.weight[:old_num_classes] = old_out.weight\n",
        "        new_out.bias[:old_num_classes] = old_out.bias\n",
        "\n",
        "    model.out = new_out.to(next(model.parameters()).device)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Y4jhQjzDymjh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before Task2:\n",
        "\n",
        "Output layer size = 2\n",
        "\n",
        "Classes = [Generic, Normal]\n",
        "\n",
        "After Task2:\n",
        "\n",
        "Output layer size = 3\n",
        "\n",
        "Classes = [Exploits, Generic, Normal]"
      ],
      "metadata": {
        "id": "BnzKB1-1EpIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = expand_output_layer(model, new_num_classes=len(le2.classes_))\n",
        "print(\"New output classes:\", model.out.out_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kgjDTCkyqaO",
        "outputId": "5cd69606-13d4-41da-a4df-e7031981c4c0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New output classes: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 15. PyTorch Dataset and DataLoader (Task 2)\n",
        "\n",
        "We convert Task 2 features and labels into PyTorch tensors and create\n",
        "DataLoaders for training and evaluation.\n",
        "\n",
        "This enables batch-based training on Task 2 while maintaining the\n",
        "same preprocessing and input feature dimension as Task 1.\n"
      ],
      "metadata": {
        "id": "FlJi_HdgFph_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "\n",
        "train_ds2 = TensorDataset(\n",
        "    torch.tensor(X2_train_np, dtype=torch.float32),\n",
        "    torch.tensor(y2_train, dtype=torch.long)\n",
        ")\n",
        "test_ds2 = TensorDataset(\n",
        "    torch.tensor(X2_test_np, dtype=torch.float32),\n",
        "    torch.tensor(y2_test, dtype=torch.long)\n",
        ")\n",
        "\n",
        "train_loader2 = DataLoader(train_ds2, batch_size=256, shuffle=True)\n",
        "test_loader2  = DataLoader(test_ds2, batch_size=256, shuffle=False)\n"
      ],
      "metadata": {
        "id": "nrC83Kocyt1G"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 16. Baseline Performance Before Learning Task 2\n",
        "\n",
        "Before training on Task 2, we evaluate the current model on Task 1 test data.\n",
        "\n",
        "This provides the reference performance used to compute forgetting after\n",
        "Task 2 training.\n"
      ],
      "metadata": {
        "id": "8AcOI3bIFurz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_t1_before, f1_t1_before = evaluate(model, test_loader1, device)\n",
        "print(\"Before Task2 training | Task1 Test Acc:\", acc_t1_before, \"| Macro-F1:\", f1_t1_before)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fHLiykRywQp",
        "outputId": "183b54e3-618b-40e5-b7c3-202ceff94914"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Task2 training | Task1 Test Acc: 0.9820121350969196 | Macro-F1: 0.6542721802050965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first build Task2 DataLoaders. Then, before training on Task2, we evaluate the model on Task1 to record baseline performance. After Task2 training, we evaluate again on Task1 â€” the difference is the forgetting metric."
      ],
      "metadata": {
        "id": "ZLbxt7gxF1CO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy remains high, but Macro-F1 shifts because the label mapping is updated when the class set expands. In the final integrated codebase we will use a consistent global label mapping to keep metric comparisons strictly aligned across tasks."
      ],
      "metadata": {
        "id": "yI4n0Q7UF-1R"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pTMQd58kGkIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 17. Task 2 Training WITHOUT Experience Replay (Baseline)\n",
        "\n",
        "now to train the expanded model on Task 2 data\n",
        "without using any replay mechanism.\n",
        "\n",
        "This allows us to observe the extent of catastrophic forgetting\n",
        "on Task 1.\n"
      ],
      "metadata": {
        "id": "m_AamffmGlu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_one_task(\n",
        "    model=model,\n",
        "    train_loader=train_loader2,\n",
        "    test_loader=test_loader2,\n",
        "    device=device,\n",
        "    y_train_for_weights=y2_train,\n",
        "    epochs=3,\n",
        "    lr=1e-4\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz9O2EpHyx7J",
        "outputId": "996a571c-c7be-477d-c1e1-7b2b8bb7b116"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 | Loss: 5.1485 | Test Acc: 0.8005 | Test Macro-F1: 0.7853\n",
            "Epoch 2/3 | Loss: 3.9804 | Test Acc: 0.8145 | Test Macro-F1: 0.8042\n",
            "Epoch 3/3 | Loss: 3.1529 | Test Acc: 0.8146 | Test Macro-F1: 0.8061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 18. Measuring Catastrophic Forgetting\n",
        "\n",
        "After training on Task 2, we evaluate the model again\n",
        "on Task 1 test data.\n",
        "\n",
        "Forgetting is computed as:\n",
        "\n",
        "Forgetting = (Task1 Macro-F1 before Task2) âˆ’ (Task1 Macro-F1 after Task2)\n",
        "\n",
        "A large drop indicates severe catastrophic forgetting.\n"
      ],
      "metadata": {
        "id": "8MpXoEhnGvNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_t1_after, f1_t1_after = evaluate(model, test_loader1, device)\n",
        "print(\"After Task2 training | Task1 Test Acc:\", acc_t1_after, \"| Macro-F1:\", f1_t1_after)\n",
        "\n",
        "print(\"\\nForgetting (Macro-F1 drop):\", f1_t1_before - f1_t1_after)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF0ql1B1y9Wd",
        "outputId": "343921cc-5739-49a1-c8ba-d8a218358760"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Task2 training | Task1 Test Acc: 0.03071360813302071 | Macro-F1: 0.026749372848815862\n",
            "\n",
            "Forgetting (Macro-F1 drop): 0.6275228073562806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training on Task 2 without replay, Task 1 Macro-F1 drops dramatically from ~0.65 to near zero. The forgetting metric is approximately 0.63, confirming severe catastrophic forgetting in the standard fine-tuning setup."
      ],
      "metadata": {
        "id": "5xZU-8y8G4W_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 19. Experience Replay (ER) â€“ Replay Buffer Implementation\n",
        "\n",
        "To mitigate catastrophic forgetting, we implement a replay buffer.\n",
        "\n",
        "The buffer:\n",
        "- Stores samples from previously learned tasks.\n",
        "- Has a fixed memory capacity.\n",
        "- Uses random replacement when full (reservoir-style behavior).\n",
        "- Allows sampling of past examples during future task training.\n",
        "\n",
        "This mechanism enables the model to rehearse previous knowledge\n",
        "while learning new classes.\n"
      ],
      "metadata": {
        "id": "P0ji6D4PHaSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.x = []\n",
        "        self.y = []\n",
        "#Adds samples from Task1 into memory.\n",
        "#If buffer is full â†’ randomly replaces existing samples.\n",
        "#Keeps memory bounded.\n",
        "\n",
        "def add_dataset(self, X, y):\n",
        "        for xi, yi in zip(X, y):\n",
        "            if len(self.y) < self.capacity:\n",
        "                self.x.append(xi)\n",
        "                self.y.append(yi)\n",
        "            else:\n",
        "                idx = random.randint(0, self.capacity - 1)\n",
        "                self.x[idx] = xi\n",
        "                self.y[idx] = yi\n",
        "                #Randomly samples old examples, Returns them as tensors, These are mixed with new task data.\n",
        "                #Limits memory size (important in real systems).\n",
        "\n",
        " def sample(self, batch_size):\n",
        "        if len(self.y) == 0:\n",
        "            return None, None\n",
        "        idx = random.sample(range(len(self.y)), min(batch_size, len(self.y)))\n",
        "        x = torch.tensor([self.x[i] for i in idx], dtype=torch.float32)\n",
        "        y = torch.tensor([self.y[i] for i in idx], dtype=torch.long)\n",
        "        return x, y\n"
      ],
      "metadata": {
        "id": "Fqe_I32HzYkk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 20. Initializing Replay Memory\n",
        "\n",
        "We initialize a replay buffer with a fixed capacity (20,000 samples).\n",
        "\n",
        "The buffer is populated with Task 1 training data before learning Task 2.\n",
        "This ensures that past knowledge is available during incremental training.\n"
      ],
      "metadata": {
        "id": "5ZmDluZ_IdPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory_size = 20000 # you can tune this later\n",
        "#It is a tunable hyperparameter balancing memory efficiency and performance.\n",
        "buffer = ReplayBuffer(capacity=memory_size)\n",
        "\n",
        "buffer.add_dataset(X1_train_np, y1_train)\n",
        "\n",
        "print(\"Replay memory size:\", len(buffer.y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqPyf3BqzbOQ",
        "outputId": "b4eac94c-a520-45eb-e3e3-c6384f517041"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replay memory size: 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 21. Task 2 Training WITH Experience Replay\n",
        "\n",
        "We define a modified training loop for Task 2 that:\n",
        "\n",
        "1. Samples a batch from Task 2.\n",
        "2. Samples a replay batch from the memory buffer.\n",
        "3. Concatenates both batches.\n",
        "4. Performs a single optimization step on the combined data.\n",
        "\n",
        "This allows the model to rehearse previous task samples while\n",
        "learning the new class.\n"
      ],
      "metadata": {
        "id": "48Gc_SmNIhxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_task2_with_er(model, train_loader, test_loader, device, buffer, y_train_for_weights, epochs=3, lr=1e-4, replay_batch_size=256):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    counts = np.bincount(y_train_for_weights)\n",
        "    weights = (counts.sum() / (len(counts) * counts)).astype(np.float32)\n",
        "    weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
        "\n",
        "    loss_fn = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "            # Sample replay\n",
        "            xr, yr = buffer.sample(replay_batch_size)\n",
        "            if xr is not None:\n",
        "                xr, yr = xr.to(device), yr.to(device)\n",
        "                xb = torch.cat([xb, xr], dim=0)\n",
        "                yb = torch.cat([yb, yr], dim=0)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = loss_fn(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        acc, f1 = evaluate(model, test_loader, device)\n",
        "        print(f\"[ER] Epoch {epoch}/{epochs} | Loss: {avg_loss:.4f} | Task2 Test F1: {f1:.4f}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "z9oA-QBwzdqB"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 22. Full ER Experiment: Re-train + Expand + Replay\n",
        "\n",
        "To ensure fair comparison:\n",
        "\n",
        "1.  re-train Task 1 from scratch.\n",
        "2. expand the classifier to include the new class.\n",
        "3. record Task 1 performance before Task 2 learning.\n",
        "4. train Task 2 using Experience Replay.\n",
        "5. measure Task 1 performance again to compute forgetting.\n",
        "\n",
        "This allows direct comparison between:\n",
        "- Standard fine-tuning (without ER)\n",
        "- Experience Replay\n"
      ],
      "metadata": {
        "id": "zIdvxV_sJgUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-train Task1 cleanly again\n",
        "model = MLPIDS(input_dim=input_dim, num_classes=len(le1.classes_)).to(device)\n",
        "model = train_one_task(model, train_loader1, test_loader1, device, y1_train, epochs=3, lr=1e-4)\n",
        "\n",
        "# Expand\n",
        "model = expand_output_layer(model, new_num_classes=len(le2.classes_))\n",
        "\n",
        "# Measure before\n",
        "acc_t1_before, f1_t1_before = evaluate(model, test_loader1, device)\n",
        "print(\"Before ER Task2 | Task1 F1:\", f1_t1_before)\n",
        "\n",
        "# Train Task2 WITH ER\n",
        "model = train_task2_with_er(\n",
        "    model=model,\n",
        "    train_loader=train_loader2,\n",
        "    test_loader=test_loader2,\n",
        "    device=device,\n",
        "    buffer=buffer,\n",
        "    y_train_for_weights=y2_train,\n",
        "    epochs=3,\n",
        "    lr=1e-4\n",
        ")\n",
        "\n",
        "# Measure forgetting\n",
        "acc_t1_after, f1_t1_after = evaluate(model, test_loader1, device)\n",
        "print(\"After ER Task2 | Task1 F1:\", f1_t1_after)\n",
        "print(\"Forgetting with ER:\", f1_t1_before - f1_t1_after)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5Ragdu6zgwi",
        "outputId": "c0d0d2b6-f846-4556-821a-e4dcac9b634d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 | Loss: 1.7547 | Test Acc: 0.9315 | Test Macro-F1: 0.9258\n",
            "Epoch 2/3 | Loss: 2.0364 | Test Acc: 0.9538 | Test Macro-F1: 0.9493\n",
            "Epoch 3/3 | Loss: 3.7698 | Test Acc: 0.9834 | Test Macro-F1: 0.9813\n",
            "Before ER Task2 | Task1 F1: 0.647409589758091\n",
            "[ER] Epoch 1/3 | Loss: 2.1896 | Task2 Test F1: 0.3545\n",
            "[ER] Epoch 2/3 | Loss: 2.3881 | Task2 Test F1: 0.4036\n",
            "[ER] Epoch 3/3 | Loss: 2.0842 | Task2 Test F1: 0.3785\n",
            "After ER Task2 | Task1 F1: 0.30631000156039284\n",
            "Forgetting with ER: 0.3410995881976982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "that is almost 50% reduction in forgetting\n",
        "\n",
        "Without replay, catastrophic forgetting is severe (F1 drop â‰ˆ 0.63). With Experience Replay, forgetting is reduced to â‰ˆ 0.34. Although performance is not fully preserved, ER significantly mitigates forgetting by rehearsing past samples during incremental training."
      ],
      "metadata": {
        "id": "uwn6S2noJ0hv"
      }
    }
  ]
}